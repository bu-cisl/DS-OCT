{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6120dd-e452-4641-ac99-c18c962a8063",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from util.data_preparation import VariedSizedImagesCollate, LoadingImgs_to_ListOfListOfTensors, VariedSizedImagesDataset, data_aug_preprocessing_HR\n",
    "import time\n",
    "import torch\n",
    "from options.train_options import TrainOptions\n",
    "from models import create_model\n",
    "from util.visualizer import Visualizer\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from collections import OrderedDict\n",
    "from util.metrics_utils import metrics_names\n",
    "def linear_normalize(tmp):\n",
    "    return (tmp - tmp.min())/(tmp.max() - tmp.min())\n",
    "\n",
    "name = '--name CUT+REG+Pseudo_4x_NCE20_REG100_TV600_MAE1_MAEpseudo10_3channel'\n",
    "model = '--model cutreg_twostage' # current proposed framework that uses CUT loss and registration loss\n",
    "mode = '--train_R_with_G True --only_train_R False --only_train_G False --train_G_pseudo True'\n",
    "hyperparameters = '--lambda_GAN 1.0 --lambda_NCE 20.0 --lambda_REG 100.0 --lambda_TV 600.0 --lambda_MAE 1.0 --lambda_MAE_pseudo 10.0 --CUT_mode FastCUT'\n",
    "lr_schedule = '--n_epochs 50 --n_epochs_decay 450'\n",
    "cmd_line = ' '.join((name, model, mode, hyperparameters, lr_schedule))\n",
    "opt = TrainOptions(cmd_line).parse()   # get training options\n",
    "model = create_model(opt)      # create a model given opt.model and other options\n",
    "## loading the image data (full FOV, HR meaning original,non-downsampled)\n",
    "data_folder = 'Dataset/example_training_data/'\n",
    "image_indices = [1, 2, 3]\n",
    "list_of_list_of_tensors = LoadingImgs_to_ListOfListOfTensors(data_folder, image_indices)\n",
    "dataset = VariedSizedImagesDataset(list_of_list_of_tensors)\n",
    "dataset_size = len(dataset) # get the number of images in the dataset.\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "            dataset,\n",
    "            batch_size=1, ## can only be 1\n",
    "            collate_fn=VariedSizedImagesCollate,\n",
    "            shuffle=not opt.serial_batches,\n",
    "            num_workers=int(opt.num_threads),\n",
    "            drop_last=True if opt.isTrain else False,\n",
    "        )\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, \n",
    "                                              sampler=torch.utils.data.RandomSampler(dataset, replacement=True, num_samples=2))\n",
    "writer = SummaryWriter('runs/'+str(opt.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda4e1a2-099f-490e-8319-ed98de71fdbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.netR.load_state_dict(torch.load('model_weights/registration_net_pretrained.pth'))\n",
    "visualizer = Visualizer(opt)   # create a visualizer that display/save images and plots\n",
    "opt.visualizer = visualizer\n",
    "total_iters = 0                # the total number of training iterations\n",
    "optimize_time = 0.1\n",
    "times = []\n",
    "for epoch in range(opt.epoch_count, opt.n_epochs + opt.n_epochs_decay + 1):    # outer loop for different epochs; we save the model by <epoch_count>, <epoch_count>+<save_latest_freq>\n",
    "    epoch_start_time = time.time()  # timer for entire epoch\n",
    "    iter_data_time = time.time()    # timer for data loading per iteration\n",
    "    epoch_iter = 0                  # the number of training iterations in current epoch, reset to 0 every epoch\n",
    "    visualizer.reset()              # reset the visualizer: make sure it saves the results to HTML at least once every epoch\n",
    "\n",
    "    model.netG.train() # switching on the training mode for netG\n",
    "    running_losses = OrderedDict()\n",
    "    for name in model.loss_names:\n",
    "        running_losses[name] = 0\n",
    "        \n",
    "    for i, data in enumerate(train_dataloader): # inner loop within one epoch\n",
    "        iter_start_time = time.time()  # timer for computation per iteration\n",
    "        if total_iters % opt.print_freq == 0:\n",
    "            t_data = iter_start_time - iter_data_time\n",
    "\n",
    "        batch_size = len(data[0])\n",
    "        total_iters += batch_size\n",
    "        epoch_iter += batch_size\n",
    "\n",
    "        if epoch == opt.epoch_count and i == 0:\n",
    "            model.data_dependent_initialize(data) \n",
    "            model.setup(opt)               # regular setup: load and print networks; create schedulers\n",
    "            model.parallelize()\n",
    "            metrics = model.save_images_FFOV(0, test_dataloader)\n",
    "            for i in range(len(metrics_names)):\n",
    "                writer.add_scalar('metric_'+str(metrics_names[i]), metrics[i], epoch)\n",
    "            \n",
    "        ## stage 1: train image translation net with CUT loss with small FOV images, register first then translate\n",
    "        ## netG, netF and netD is trainable, netR is fixed\n",
    "        \n",
    "        model.set_input(data)\n",
    "        model.define_fold(data)\n",
    "        model.forward_stage2()\n",
    "#         real_A, real_B = model.real_A.detach().cpu().numpy(), model.real_B_reg.detach().cpu().numpy()\n",
    "            \n",
    "        # data_aug_preprocessing_HR crops large image into small patches\n",
    "        mini_dataloader = model.patchify_WSI(real_B_reg = model.real_B_reg)       \n",
    "        for i, mini_data in enumerate(mini_dataloader):\n",
    "            if len(opt.gpu_ids) > 0:\n",
    "                torch.cuda.synchronize()\n",
    "            optimize_start_time = time.time()\n",
    "            model.set_mini_input(mini_data)\n",
    "            model.optimize_parameters()\n",
    "            \n",
    "            total_iters += model.mini_bs\n",
    "            epoch_iter += model.mini_bs\n",
    "            if len(opt.gpu_ids) > 0:\n",
    "                torch.cuda.synchronize()\n",
    "            optimize_time = (time.time() - optimize_start_time) / batch_size * 0.005 + 0.995 * optimize_time\n",
    "            losses = model.get_current_losses()\n",
    "            for name in model.loss_names:\n",
    "                if isinstance(name, str):\n",
    "                    running_losses[name] += losses[name] \n",
    "                \n",
    "        ## stage 2: train image registration across full FOV, translate first then register\n",
    "        ## netR is trainable, netG, netF, netD are fixed\n",
    "        if not model.opt.only_train_G:\n",
    "            model.set_input(data)\n",
    "            fake_B = model.patch_wise_predict(input_data=model.real_A_eq, stride_ratio=1).permute(2,0,1).unsqueeze(0)\n",
    "            \n",
    "            if len(opt.gpu_ids) > 0:\n",
    "                torch.cuda.synchronize()            \n",
    "            optimize_start_time = time.time()\n",
    "            model.set_input(data)\n",
    "            ## gradient descend on netR\n",
    "            model.optimize_parameters_stage2(fake_B = fake_B)\n",
    "                \n",
    "            model.netG.train()\n",
    "            if len(opt.gpu_ids) > 0:\n",
    "                torch.cuda.synchronize()\n",
    "            optimize_time = (time.time() - optimize_start_time) / batch_size * 0.005 + 0.995 * optimize_time\n",
    "            \n",
    "        losses = model.get_current_losses()\n",
    "        for name in model.loss_names:\n",
    "            if isinstance(name, str):\n",
    "                running_losses[name] += losses[name] \n",
    "        visualizer.print_current_losses(epoch, epoch_iter, losses, optimize_time, t_data)\n",
    "        if opt.display_id is None or opt.display_id > 0:\n",
    "            visualizer.plot_current_losses(epoch, float(epoch_iter) / dataset_size, losses)\n",
    "\n",
    "        iter_data_time = time.time()\n",
    "\n",
    "    if epoch % opt.save_epoch_freq == 0:              # cache our model every <save_epoch_freq> epochs\n",
    "        print('saving the model at the end of epoch %d, iters %d' % (epoch, total_iters))\n",
    "#         model.save_networks('latest')\n",
    "#         model.save_networks(epoch)\n",
    "        metrics = model.save_images_FFOV(epoch, test_dataloader)\n",
    "        for i in range(len(metrics_names)):\n",
    "            writer.add_scalar('metric_'+str(metrics_names[i]), metrics[i], epoch)\n",
    "\n",
    "    print('End of epoch %d / %d \\t Time Taken: %d sec' % (epoch, opt.n_epochs + opt.n_epochs_decay, time.time() - epoch_start_time))\n",
    "    model.update_learning_rate()                     # update learning rates at the end of every epoch.\n",
    "    for name in model.loss_names:\n",
    "        if isinstance(name, str):\n",
    "            writer.add_scalar('loss_'+str(name), running_losses[name]/len(train_dataloader), epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
