{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce564fba-58ec-4121-961b-e066332c1ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from util.data_preparation import VariedSizedImagesCollate, LoadingImgs_to_ListOfListOfTensors, VariedSizedImagesDataset, data_aug_preprocessing_HR, patch_wise_predict\n",
    "import time\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from options.train_options import TrainOptions\n",
    "from models import create_model\n",
    "def linear_normalize(tmp):\n",
    "    return (tmp - tmp.min())/(tmp.max() - tmp.min())\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "import imageio\n",
    "\n",
    "'''load data'''\n",
    "data_folder = 'dataset/example_testing_data/'\n",
    "image_indices = [1, 2, 3]\n",
    "list_of_list_of_tensors = LoadingImgs_to_ListOfListOfTensors(data_folder, image_indices)\n",
    "dataset = VariedSizedImagesDataset(list_of_list_of_tensors)\n",
    "## batch_size can only be 1\n",
    "dataloader = torch.utils.data.DataLoader(dataset,batch_size=1, collate_fn=VariedSizedImagesCollate, shuffle=False,\n",
    "                                         num_workers=0, drop_last=True)\n",
    "\n",
    "'''create model and load model weights'''\n",
    "model = '--model cutreg_twostage'\n",
    "opt = TrainOptions(model).parse()   # get training options\n",
    "opt.input_nc = 3\n",
    "model = create_model(opt)      # create a model given opt.model and other options\n",
    "\n",
    "'''CUT model weights'''\n",
    "# G_weights_name = 'CUT_net_G'\n",
    "\n",
    "'''FastCUT model weights'''\n",
    "# G_weights_name = 'FastCUT_net_G'\n",
    "\n",
    "'''Pseudo + CUT + REG model weights'''\n",
    "G_weights_name = 'CUT+REG+Pseudo_net_G'\n",
    "\n",
    "'''ablation study'''\n",
    "'''Pseudo + CUT model weights'''\n",
    "# G_weights_name = 'CUT+Pseudo_net_G'\n",
    "\n",
    "'''CUT + REG model weights'''\n",
    "# G_weights_name = 'CUT+REG_net_G'\n",
    "\n",
    "'''Registration only'''\n",
    "# G_weights_name = 'PreREG_net_G'\n",
    "\n",
    "'''Pseudo label only'''\n",
    "# G_weights_name = 'PseudoSupervised_net_G'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcfada0-f873-4543-92e0-da81f478e24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''generate DS results from netG'''\n",
    "model.netG.load_state_dict(torch.load('model_weights/'+G_weights_name+'.pth'))\n",
    "\n",
    "img_dir = 'test_results/' + G_weights_name + '/'\n",
    "if not os.path.exists(img_dir):\n",
    "    os.makedirs(img_dir)\n",
    "    print(f'Directory {img_dir} created')\n",
    "else:\n",
    "    print(f'Directory {img_dir} already exists')\n",
    "\n",
    "for i, data in enumerate(dataloader):\n",
    "    model.set_input(data)\n",
    "    fake_B = model.patch_wise_predict(input_data=model.real_A_eq, bs=4, stride_ratio=4).cpu().numpy()\n",
    "    Image.fromarray((fake_B*255).astype(np.uint8)).save(img_dir + 'translated_' + str(i + 1) + '.png')\n",
    "    np.save(img_dir + 'translated_' + str(i + 1) + '.npy', fake_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de955c98-5231-4835-9c8a-b63178da1666",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''generate registration results from netR'''\n",
    "R_weights_name = 'registration_net_R'\n",
    "model.netR.load_state_dict(torch.load('model_weights/'+R_weights_name+'.pth'))\n",
    "test_R_target_list_numpy = []\n",
    "test_R_moving_OD_list_numpy = []\n",
    "test_R_OD_list_numpy = []\n",
    "test_R_GS_list_numpy = []\n",
    "img_dir = 'test_results/' + R_weights_name + '/'\n",
    "if not os.path.exists(img_dir):\n",
    "    os.makedirs(img_dir)\n",
    "    print(f'Directory {img_dir} created')\n",
    "else:\n",
    "    print(f'Directory {img_dir} already exists')\n",
    "for i, data in enumerate(dataloader):\n",
    "    model.set_input(data)\n",
    "    model.forward_stage2()\n",
    "    test_R_target_list_numpy.append(1.0 - model.real_A_eq.permute(0,2,3,1)[:,:,:,0].squeeze().detach().cpu().numpy())\n",
    "    test_R_moving_OD_list_numpy.append(1.0 - model.fake_A_eq.permute(0,2,3,1)[:,:,:,0].squeeze().detach().cpu().numpy())\n",
    "    model.forward_stage2()\n",
    "    test_R_OD_list_numpy.append(1.0 - model.fake_A_reg_eq.permute(0,2,3,1).squeeze().detach().cpu().numpy())\n",
    "    test_R_GS_list_numpy.append(model.real_B_reg.permute(0,2,3,1).squeeze().detach().cpu().numpy())\n",
    "\n",
    "for i in range(len(test_R_target_list_numpy)):\n",
    "    imageio.imwrite(img_dir+'OCT_eq'+str(i + 1)+'.tif', (test_R_target_list_numpy[i]*255).astype(np.uint8))\n",
    "    imageio.imwrite(img_dir+'moving_OD'+str(i + 1)+'.tif', (test_R_moving_OD_list_numpy[i]*255).astype(np.uint8))\n",
    "    imageio.imwrite(img_dir+'moved_OD'+str(i + 1)+'.tif', (test_R_OD_list_numpy[i]*255).astype(np.uint8))\n",
    "    imageio.imwrite(img_dir+'moved_GS'+str(i + 1)+'.tif', (test_R_GS_list_numpy[i]*255).astype(np.uint8))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
